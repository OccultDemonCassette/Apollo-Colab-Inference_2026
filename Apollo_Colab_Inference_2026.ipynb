{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸµ Apollo Audio Restoration â€” Fork 5 (Unified)\n",
    "\n",
    "*Original work: [Apollo: Band-sequence Modeling for High-Quality Music Restoration in Compressed Audio](https://github.com/JusperLee/Apollo)*\n",
    "\n",
    "The Apollo model was trained to restore and enhance lossy MP3 audio (â‰¤ 128 kbps).\n",
    "\n",
    "---\n",
    "\n",
    "### What's in Fork 5?\n",
    "\n",
    "This notebook merges the best features from four community forks into one unified implementation:\n",
    "\n",
    "| Feature | Source |\n",
    "|---|---|\n",
    "| Core chunked overlap-windowed inference engine | Fork 1 Â· jarredou |\n",
    "| Configurable sample rate, output bit-depth, gain staging, fade size, CUDA device | Fork 2 Â· ibratabian17 |\n",
    "| Directory batch mode, multi-format input, shlex-safe path handling | Fork 3 Â· Losses |\n",
    "| `weights_only=False` PyTorch â‰¥ 2.0 fix, Baicai1145 Vocal MSST model, on-demand downloads | Fork 4 Â· Qupci |\n",
    "\n",
    "---\n",
    "\n",
    "### Available Models\n",
    "\n",
    "| Model | Best for | Recommended chunk_size |\n",
    "|---|---|---|\n",
    "| **MP3 Enhancer** | General lossy audio restoration | 25 |\n",
    "| **Lew Vocal Enhancer v1** | Separated vocal stems | 25 |\n",
    "| **Lew Vocal Enhancer v2 (beta)** | Separated vocal stems (improved) | 25 |\n",
    "| **Lew Universal Lossy Enhancer** | Mixed music & vocals | 19 |\n",
    "| **Baicai1145 Vocal MSST** | Separated vocal stems (community model) | 10â€“15 |\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Start\n",
    "\n",
    "1. Run **Cell 1** to install dependencies and patch the Apollo repo.\n",
    "2. *(Optional)* Run **Cell 2** to mount Google Drive.\n",
    "3. Run **Cell 3** to download only the model(s) you want.\n",
    "4. Run **Cell 4** to process a single file **or** run **Cell 5** for batch directory processing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form"
   },
   "source": [
    "#@title âš™ï¸ Cell 1 â€” Install Dependencies & Patch Apollo Repo\n",
    "#@markdown Run this cell first. It clones the Apollo repository, applies the\n",
    "#@markdown `base_model.py` patch (PyTorch â‰¥ 2.0 compatibility + Baicai checkpoint\n",
    "#@markdown support), replaces `inference.py` with the Fork 5 unified version,\n",
    "#@markdown and pins PyTorch to a known-good version.\n",
    "#@markdown\n",
    "#@markdown **Estimated time: ~3â€“5 minutes** (PyTorch reinstall is the slow part).\n",
    "\n",
    "import subprocess, sys, os\n",
    "\n",
    "def run(cmd, **kwargs):\n",
    "    \"\"\"Run a shell command, stream output, and raise on failure.\"\"\"\n",
    "    result = subprocess.run(cmd, shell=True, **kwargs)\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"Command failed (exit {result.returncode}): {cmd}\")\n",
    "\n",
    "print(\"[1/6] Cloning JusperLee/Apollo...\")\n",
    "run(\"git clone --quiet https://github.com/JusperLee/Apollo.git /content/Apollo\")\n",
    "\n",
    "print(\"[2/6] Creating model and config directories...\")\n",
    "os.makedirs(\"/content/Apollo/model\", exist_ok=True)\n",
    "os.makedirs(\"/content/Apollo/configs\", exist_ok=True)\n",
    "os.makedirs(\"/content/input_audio\", exist_ok=True)\n",
    "os.makedirs(\"/content/output_audio\", exist_ok=True)\n",
    "\n",
    "print(\"[3/6] Applying base_model.py patch (PyTorch â‰¥ 2.0 fix + Baicai support)...\")\n",
    "run(\n",
    "    \"wget -q 'https://raw.githubusercontent.com/Qupci/Apollo-Colab-Inference/main/base_model.py' \"\n",
    "    \"-O /content/Apollo/look2hear/models/base_model.py\"\n",
    ")\n",
    "\n",
    "print(\"[4/6] Installing Fork 5 unified inference.py...\")\n",
    "run(\n",
    "    \"wget -q 'https://raw.githubusercontent.com/YOUR_USERNAME/Apollo-Colab-Fork5/main/inference.py' \"\n",
    "    \"-O /content/Apollo/inference.py\"\n",
    ")\n",
    "# â†‘ Replace YOUR_USERNAME with your GitHub username after uploading inference.py\n",
    "\n",
    "print(\"[5/6] Installing Python dependencies...\")\n",
    "run(f\"{sys.executable} -m pip install -q omegaconf ml_collections\")\n",
    "\n",
    "print(\"[6/6] Pinning PyTorch to 2.5.1 + CUDA 12.4 for compatibility...\")\n",
    "run(f\"{sys.executable} -m pip uninstall -q -y torch torchvision torchaudio\")\n",
    "run(\n",
    "    f\"{sys.executable} -m pip install -q \"\n",
    "    \"torch==2.5.1 torchvision torchaudio \"\n",
    "    \"--index-url https://download.pytorch.org/whl/cu124\"\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Setup complete! Default audio folders:\")\n",
    "print(\"   Input  â†’ /content/input_audio\")\n",
    "print(\"   Output â†’ /content/output_audio\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form"
   },
   "source": [
    "#@title ğŸ“‚ Cell 2 â€” Mount Google Drive  (optional)\n",
    "#@markdown Mount your Google Drive if your audio files are stored there,\n",
    "#@markdown or if you want to save outputs directly to Drive.\n",
    "#@markdown After mounting, your Drive is available at `/content/drive/MyDrive/`.\n",
    "#@markdown\n",
    "#@markdown **Skip this cell** if you are uploading files directly to Colab.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "print(\"âœ… Google Drive mounted at /content/drive/MyDrive/\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form"
   },
   "source": [
    "#@title ğŸ“¥ Cell 3 â€” Download Models\n",
    "#@markdown Select which models to download. Only the checked models will be\n",
    "#@markdown fetched. You can re-run this cell at any time to add more models.\n",
    "#@markdown Downloads are skipped if the file already exists.\n",
    "\n",
    "import os, subprocess\n",
    "\n",
    "# â”€â”€ Model selection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "download_mp3_enhancer          = True  #@param {type:\"boolean\"}\n",
    "download_lew_vocal_v1          = True  #@param {type:\"boolean\"}\n",
    "download_lew_vocal_v2          = True  #@param {type:\"boolean\"}\n",
    "download_lew_universal         = True  #@param {type:\"boolean\"}\n",
    "download_baicai_vocal_msst     = False #@param {type:\"boolean\"}\n",
    "\n",
    "# â”€â”€ Download helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def download(url, dest_path, label):\n",
    "    \"\"\"Download `url` to `dest_path` using wget with resume support.\n",
    "    Skips the download if the file already exists and is non-empty.\"\"\"\n",
    "    if os.path.exists(dest_path) and os.path.getsize(dest_path) > 0:\n",
    "        print(f\"  â­  {label} â€” already downloaded, skipping.\")\n",
    "        return\n",
    "    os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "    print(f\"  â¬‡  {label}...\")\n",
    "    result = subprocess.run(\n",
    "        [\"wget\", \"-q\", \"-c\", \"--show-progress\", \"-O\", dest_path, url]\n",
    "    )\n",
    "    if result.returncode != 0:\n",
    "        print(f\"  âŒ  Failed to download {label} (exit {result.returncode})\")\n",
    "    else:\n",
    "        print(f\"  âœ…  {label} saved to {dest_path}\")\n",
    "\n",
    "MODEL_DIR  = \"/content/Apollo/model\"\n",
    "CONFIG_DIR = \"/content/Apollo/configs\"\n",
    "\n",
    "print(\"Downloading selected models...\\n\")\n",
    "\n",
    "if download_mp3_enhancer:\n",
    "    download(\n",
    "        \"https://huggingface.co/JusperLee/Apollo/resolve/main/pytorch_model.bin\",\n",
    "        f\"{MODEL_DIR}/pytorch_model.bin\",\n",
    "        \"MP3 Enhancer (pytorch_model.bin)\"\n",
    "    )\n",
    "\n",
    "if download_lew_vocal_v1:\n",
    "    download(\n",
    "        \"https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/apollo_model.ckpt\",\n",
    "        f\"{MODEL_DIR}/apollo_model.ckpt\",\n",
    "        \"Lew Vocal Enhancer v1\"\n",
    "    )\n",
    "\n",
    "if download_lew_vocal_v2:\n",
    "    download(\n",
    "        \"https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/apollo_model_v2.ckpt\",\n",
    "        f\"{MODEL_DIR}/apollo_model_v2.ckpt\",\n",
    "        \"Lew Vocal Enhancer v2 (beta)\"\n",
    "    )\n",
    "    download(\n",
    "        \"https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/config_apollo_vocal.yaml\",\n",
    "        f\"{CONFIG_DIR}/config_apollo_vocal.yaml\",\n",
    "        \"Config: config_apollo_vocal.yaml\"\n",
    "    )\n",
    "\n",
    "if download_lew_universal:\n",
    "    download(\n",
    "        \"https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/download/uni/apollo_model_uni.ckpt\",\n",
    "        f\"{MODEL_DIR}/apollo_model_uni.ckpt\",\n",
    "        \"Lew Universal Lossy Enhancer\"\n",
    "    )\n",
    "    download(\n",
    "        \"https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/download/uni/config_apollo_uni.yaml\",\n",
    "        f\"{CONFIG_DIR}/config_apollo_uni.yaml\",\n",
    "        \"Config: config_apollo_uni.yaml\"\n",
    "    )\n",
    "\n",
    "if download_baicai_vocal_msst:\n",
    "    download(\n",
    "        \"https://huggingface.co/baicai1145/Apollo-vocal-msst/resolve/main/model_apollo_0129_-21.98.ckpt\",\n",
    "        f\"{MODEL_DIR}/baicai_apollo_vocal_msst.ckpt\",\n",
    "        \"Baicai1145 Vocal MSST\"\n",
    "    )\n",
    "    download(\n",
    "        \"https://huggingface.co/baicai1145/Apollo-vocal-msst/resolve/main/config_apollo_0129_-21.98.yaml\",\n",
    "        f\"{CONFIG_DIR}/config_baicai_vocal_msst.yaml\",\n",
    "        \"Config: config_baicai_vocal_msst.yaml\"\n",
    "    )\n",
    "\n",
    "print(\"\\nâœ… Model download step complete.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form"
   },
   "source": [
    "#@title ğŸ§ Cell 4 â€” Single File Inference\n",
    "#@markdown Process one audio file. Supports WAV, MP3, FLAC, M4A, OPUS, OGG, AIFF.\n",
    "#@markdown\n",
    "#@markdown **Tip:** Upload your file to `/content/input_audio/` using the\n",
    "#@markdown file browser on the left, then set `input_file` below.\n",
    "\n",
    "import os, shlex, subprocess\n",
    "%cd /content/Apollo\n",
    "\n",
    "# â”€â”€ I/O â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "input_file  = \"/content/input_audio/input.wav\"  #@param {type:\"string\"}\n",
    "output_file = \"/content/output_audio/output.wav\" #@param {type:\"string\"}\n",
    "\n",
    "# â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model = \"Lew Universal Lossy Enhancer\"  #@param [\"MP3 Enhancer\", \"Lew Vocal Enhancer v1\", \"Lew Vocal Enhancer v2 (beta)\", \"Lew Universal Lossy Enhancer\", \"Baicai1145 Vocal MSST\"]\n",
    "\n",
    "# â”€â”€ Processing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#@markdown ---\n",
    "#@markdown #### Processing Settings\n",
    "#@markdown *Use `chunk_size=19` for Lew Universal, `chunk_size=25` for other models.*\n",
    "#@markdown *Use `chunk_size=10` for Baicai Vocal MSST.*\n",
    "chunk_size = 19  #@param {type:\"slider\", min:3, max:25, step:1}\n",
    "overlap    = 2   #@param {type:\"slider\", min:2, max:10, step:1}\n",
    "fade_sec   = 3   #@param {type:\"slider\", min:1, max:10, step:1}\n",
    "sample_rate = 44100  #@param {type:\"number\"}\n",
    "\n",
    "# â”€â”€ Audio Quality â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#@markdown ---\n",
    "#@markdown #### Audio Quality\n",
    "out_subtype = \"FLOAT\"  #@param [\"FLOAT\", \"PCM_24\", \"PCM_16\"]\n",
    "#@markdown `FLOAT` (32-bit) is recommended â€” it avoids clipping and preserves full dynamic range.\n",
    "gain_in  = 0  #@param {type:\"slider\", min:-24, max:24, step:0.5}\n",
    "gain_out = 0  #@param {type:\"slider\", min:-24, max:24, step:0.5}\n",
    "#@markdown `gain_in` / `gain_out` adjust level in dB before / after inference.\n",
    "\n",
    "# â”€â”€ Hardware â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cuda_device = \"0\"  #@param {type:\"string\"}\n",
    "\n",
    "# â”€â”€ Resolve checkpoint & config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MODEL_DIR  = \"/content/Apollo/model\"\n",
    "CONFIG_DIR = \"/content/Apollo/configs\"\n",
    "\n",
    "model_map = {\n",
    "    \"MP3 Enhancer\": {\n",
    "        \"ckpt\":   f\"{MODEL_DIR}/pytorch_model.bin\",\n",
    "        \"config\": f\"{CONFIG_DIR}/apollo.yaml\",\n",
    "    },\n",
    "    \"Lew Vocal Enhancer v1\": {\n",
    "        \"ckpt\":   f\"{MODEL_DIR}/apollo_model.ckpt\",\n",
    "        \"config\": f\"{CONFIG_DIR}/apollo.yaml\",\n",
    "    },\n",
    "    \"Lew Vocal Enhancer v2 (beta)\": {\n",
    "        \"ckpt\":   f\"{MODEL_DIR}/apollo_model_v2.ckpt\",\n",
    "        \"config\": f\"{CONFIG_DIR}/config_apollo_vocal.yaml\",\n",
    "    },\n",
    "    \"Lew Universal Lossy Enhancer\": {\n",
    "        \"ckpt\":   f\"{MODEL_DIR}/apollo_model_uni.ckpt\",\n",
    "        \"config\": f\"{CONFIG_DIR}/config_apollo_uni.yaml\",\n",
    "    },\n",
    "    \"Baicai1145 Vocal MSST\": {\n",
    "        \"ckpt\":   f\"{MODEL_DIR}/baicai_apollo_vocal_msst.ckpt\",\n",
    "        \"config\": f\"{CONFIG_DIR}/config_baicai_vocal_msst.yaml\",\n",
    "    },\n",
    "}\n",
    "\n",
    "selected = model_map[model]\n",
    "ckpt_path   = selected[\"ckpt\"]\n",
    "config_path = selected[\"config\"]\n",
    "\n",
    "# Validate that the required files exist\n",
    "missing = [p for p in (ckpt_path, config_path) if not os.path.exists(p)]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        f\"The following required files are missing:\\n\" +\n",
    "        \"\\n\".join(f\"  {p}\" for p in missing) +\n",
    "        \"\\nPlease run Cell 3 to download the selected model first.\"\n",
    "    )\n",
    "\n",
    "if not os.path.exists(input_file):\n",
    "    raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(os.path.dirname(os.path.abspath(output_file)), exist_ok=True)\n",
    "\n",
    "# â”€â”€ Build & run command â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cmd = (\n",
    "    f\"python inference.py \"\n",
    "    f\"--in_wav  {shlex.quote(input_file)} \"\n",
    "    f\"--out_wav {shlex.quote(output_file)} \"\n",
    "    f\"--ckpt    {shlex.quote(ckpt_path)} \"\n",
    "    f\"--config  {shlex.quote(config_path)} \"\n",
    "    f\"--chunk_size {chunk_size} \"\n",
    "    f\"--overlap    {overlap} \"\n",
    "    f\"--fade_sec   {fade_sec} \"\n",
    "    f\"--sr         {sample_rate} \"\n",
    "    f\"--out_subtype {shlex.quote(out_subtype)} \"\n",
    "    f\"--gain_in  {gain_in} \"\n",
    "    f\"--gain_out {gain_out} \"\n",
    "    f\"--cuda     {shlex.quote(cuda_device)}\"\n",
    ")\n",
    "\n",
    "print(f\"Model    : {model}\")\n",
    "print(f\"Input    : {input_file}\")\n",
    "print(f\"Output   : {output_file}\")\n",
    "print()\n",
    "get_ipython().system(cmd)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form"
   },
   "source": [
    "#@title ğŸ“ Cell 5 â€” Batch Directory Inference\n",
    "#@markdown Process **all** audio files in a directory.\n",
    "#@markdown Supports: WAV, MP3, FLAC, M4A, OPUS, OGG, AIFF.\n",
    "#@markdown All outputs are saved as WAV to the output directory.\n",
    "#@markdown\n",
    "#@markdown The model is loaded **once** and reused for every file,\n",
    "#@markdown making this much more efficient than running Cell 4 repeatedly.\n",
    "#@markdown Failed files are skipped with a warning rather than halting the batch.\n",
    "\n",
    "import os, shlex\n",
    "%cd /content/Apollo\n",
    "\n",
    "# â”€â”€ I/O â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "input_directory  = \"/content/input_audio\"   #@param {type:\"string\"}\n",
    "output_directory = \"/content/output_audio\"  #@param {type:\"string\"}\n",
    "\n",
    "# â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model = \"Lew Universal Lossy Enhancer\"  #@param [\"MP3 Enhancer\", \"Lew Vocal Enhancer v1\", \"Lew Vocal Enhancer v2 (beta)\", \"Lew Universal Lossy Enhancer\", \"Baicai1145 Vocal MSST\"]\n",
    "\n",
    "# â”€â”€ Processing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#@markdown ---\n",
    "#@markdown #### Processing Settings\n",
    "chunk_size  = 19   #@param {type:\"slider\", min:3, max:25, step:1}\n",
    "overlap     = 2    #@param {type:\"slider\", min:2, max:10, step:1}\n",
    "fade_sec    = 3    #@param {type:\"slider\", min:1, max:10, step:1}\n",
    "sample_rate = 44100 #@param {type:\"number\"}\n",
    "\n",
    "# â”€â”€ Audio Quality â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#@markdown ---\n",
    "#@markdown #### Audio Quality\n",
    "out_subtype = \"FLOAT\"  #@param [\"FLOAT\", \"PCM_24\", \"PCM_16\"]\n",
    "gain_in  = 0  #@param {type:\"slider\", min:-24, max:24, step:0.5}\n",
    "gain_out = 0  #@param {type:\"slider\", min:-24, max:24, step:0.5}\n",
    "\n",
    "# â”€â”€ Hardware â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cuda_device = \"0\"  #@param {type:\"string\"}\n",
    "\n",
    "# â”€â”€ Resolve checkpoint & config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MODEL_DIR  = \"/content/Apollo/model\"\n",
    "CONFIG_DIR = \"/content/Apollo/configs\"\n",
    "\n",
    "model_map = {\n",
    "    \"MP3 Enhancer\": {\n",
    "        \"ckpt\":   f\"{MODEL_DIR}/pytorch_model.bin\",\n",
    "        \"config\": f\"{CONFIG_DIR}/apollo.yaml\",\n",
    "    },\n",
    "    \"Lew Vocal Enhancer v1\": {\n",
    "        \"ckpt\":   f\"{MODEL_DIR}/apollo_model.ckpt\",\n",
    "        \"config\": f\"{CONFIG_DIR}/apollo.yaml\",\n",
    "    },\n",
    "    \"Lew Vocal Enhancer v2 (beta)\": {\n",
    "        \"ckpt\":   f\"{MODEL_DIR}/apollo_model_v2.ckpt\",\n",
    "        \"config\": f\"{CONFIG_DIR}/config_apollo_vocal.yaml\",\n",
    "    },\n",
    "    \"Lew Universal Lossy Enhancer\": {\n",
    "        \"ckpt\":   f\"{MODEL_DIR}/apollo_model_uni.ckpt\",\n",
    "        \"config\": f\"{CONFIG_DIR}/config_apollo_uni.yaml\",\n",
    "    },\n",
    "    \"Baicai1145 Vocal MSST\": {\n",
    "        \"ckpt\":   f\"{MODEL_DIR}/baicai_apollo_vocal_msst.ckpt\",\n",
    "        \"config\": f\"{CONFIG_DIR}/config_baicai_vocal_msst.yaml\",\n",
    "    },\n",
    "}\n",
    "\n",
    "selected    = model_map[model]\n",
    "ckpt_path   = selected[\"ckpt\"]\n",
    "config_path = selected[\"config\"]\n",
    "\n",
    "# Validate model files\n",
    "missing = [p for p in (ckpt_path, config_path) if not os.path.exists(p)]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing required files:\\n\" +\n",
    "        \"\\n\".join(f\"  {p}\" for p in missing) +\n",
    "        \"\\nPlease run Cell 3 to download the selected model first.\"\n",
    "    )\n",
    "\n",
    "if not os.path.isdir(input_directory):\n",
    "    raise NotADirectoryError(f\"Input directory not found: {input_directory}\")\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# â”€â”€ Build & run command â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cmd = (\n",
    "    f\"python inference.py \"\n",
    "    f\"--in_dir  {shlex.quote(input_directory)} \"\n",
    "    f\"--out_dir {shlex.quote(output_directory)} \"\n",
    "    f\"--ckpt    {shlex.quote(ckpt_path)} \"\n",
    "    f\"--config  {shlex.quote(config_path)} \"\n",
    "    f\"--chunk_size {chunk_size} \"\n",
    "    f\"--overlap    {overlap} \"\n",
    "    f\"--fade_sec   {fade_sec} \"\n",
    "    f\"--sr         {sample_rate} \"\n",
    "    f\"--out_subtype {shlex.quote(out_subtype)} \"\n",
    "    f\"--gain_in  {gain_in} \"\n",
    "    f\"--gain_out {gain_out} \"\n",
    "    f\"--cuda     {shlex.quote(cuda_device)}\"\n",
    ")\n",
    "\n",
    "print(f\"Model  : {model}\")\n",
    "print(f\"Input  : {input_directory}\")\n",
    "print(f\"Output : {output_directory}\")\n",
    "print()\n",
    "get_ipython().system(cmd)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
